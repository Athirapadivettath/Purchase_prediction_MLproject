# -*- coding: utf-8 -*-
"""Purchase_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-t60nONXxHivcI7LvLKMYoO7SFp8cj62

# **Project: Purchase Intention Prediction + Behavior Analysis**
**Author:** Athira P

---

## 1. Project Aim
To build a machine learning model that predicts whether an online visitor will make a purchase (Revenue = True) on an e-commerce website.

---

## 2. Objective
The goal is to analyze visitor behavior and session data to identify key factors influencing purchase decisions. By understanding visitor interactions, duration, traffic type, and demographics, this model can help e-commerce platforms optimize their marketing strategies and website experience to increase conversions.

---

## 3. Process

This notebook performs the following steps to predict customer purchase intention:

1. Install & Import Libraries:
Set up all required Python libraries such as pandas, numpy, seaborn, matplotlib, scikit-learn, imblearn, lightgbm, and xgboost.

2. Load & Preprocess Data:
Load the Online Shoppers Intention Dataset. Perform data cleaning including:

* Handling missing values

* Detecting and correcting skewness in numerical features using log/sqrt and Yeo-Johnson transformations

* Handling outliers using the Z-score method

* Encoding categorical variables and scaling numerical features

* Selecting relevant features for modeling

3. Train-Test Split & Imbalance Handling:
Split the dataset into training and testing sets (80/20). Handle class imbalance on the training set using SMOTE to balance the target variable.

4. Model Training & Evaluation:
Train multiple machine learning models including Logistic Regression, Random Forest, and LightGBM. Evaluate their performance on the test set using metrics such as Accuracy, Precision, Recall, F1-Score, Confusion Matrix, and ROC-AUC.

5. Feature Importance & Insights:
Analyze the best-performing model using feature importance plots to identify the most influential features affecting purchase intention. Generate actionable insights from model predictions.

6. Final Predicted Customers:
Use the trained model to predict customers with a high likelihood of purchase intention. Automatically generate a summary table, distribution plot, and save the predicted customers list to CSV for reporting or business decisions.

STEP 1: IMPORT LIBRARIES
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

"""STEP 2 ‚Äî IMPORT DATASET"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('Online purchase.csv')
print(" Dataset Loaded Successfully!‚úÖ")
print(f"Shape of the data: {df.shape}")
df.head()

"""STEP 2.1 ‚Äî Basic Dataset Information

info() helps us understand the data types and missing values.

describe() gives statistical summaries for numerical and categorical variables. Together, these help us identify the nature of the dataset and potential preprocessing steps.
"""

print("\n--- Dataset Info ---")
print(df.info())

print("\n--- Summary Statistics ---")
print(df.describe())

"""STEP 2.2- Checking Duplicates"""

df.duplicated().sum()

"""STEP 2.3-Removing Duplicates"""

df = df.drop_duplicates()
df.shape

"""Shape of the data (before): (12330, 18)

Shape of the data (after): (12205, 18)

**STEP 3 ‚Äî Finding Missing Values**

Missing values can affect model performance. isnull().sum(), we check for missing values and decide whether to fill or drop them.
"""

print("\n--- Missing or Null Values ---")
print(df.isnull().sum())

"""This dataset usually contains no missing values‚Äîbut verifying is essential.

STEP 4 ‚Äî Understanding Feature Types & Separate Numerical & Categorical Columns

Separating numerical and categorical features is important because the preprocessing steps for each type are different.


*   Numerical features ‚Üí scaling, outlier detection
*   Categorical features ‚Üí encoding
"""

numerical_cols = [
    'Administrative', 'Administrative_Duration', 'Informational',
    'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',
    'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay',
    'OperatingSystems', 'Browser', 'Region', 'TrafficType'
]

categorical_cols = ['Month', 'VisitorType', 'Weekend']
target = 'Revenue'

"""STEP 4.1 -Categorical Data Analysis"""

for col in categorical_cols:
    plt.figure(figsize=(8,5))
    ax = sns.countplot(x=col, data=df, palette="pastel")

    # Add value labels on top of each bar
    for p in ax.patches:
        height = p.get_height()
        ax.text(x=p.get_x() + p.get_width()/2,
                y=height + 0.5,
                s=int(height),
                ha='center')

    plt.title(f"Count of {col}")
    plt.show()

    # Print percentages
    print(f"\n{col} distribution (percentages):")
    print(round(df[col].value_counts(normalize=True) * 100, 2))
    print("-"*50)

"""Categorical Feature Distribution Summary

*Weekend*

Most sessions (76.58%) occurred on weekdays, while 23.42% occurred on weekends.

This suggests that user behavior may vary by day of the week, and the model could capture this pattern.

*VisitorType*

A vast majority of users (85.46%) are Returning Visitors, 13.87% are New Visitors, and a very small portion (0.66%) is labeled as Other.

This indicates that purchase intention is likely influenced by prior site familiarity and returning users dominate the dataset.

*Month*

The dataset has seasonal trends in session counts:

May (27.28%) and November (24.43%) have the highest traffic.

Months like February (1.48%), June (2.34%), and July (3.54%) have much lower traffic.

This can indicate that marketing campaigns, promotions, or seasonal shopping patterns may influence user behavior.

STEP 4.2- Numerical Data Analysis
"""

for col in numerical_cols:
    plt.figure(figsize=(12,5))

    # Histogram + KDE
    plt.subplot(1,2,1)
    sns.histplot(df[col], kde=True, color='skyblue')
    plt.title(f'Histogram of {col}')

    # Boxplot
    plt.subplot(1,2,2)
    sns.boxplot(x=df[col], color='lightgreen')
    plt.title(f'Boxplot of {col}')

    plt.tight_layout()
    plt.show()

"""STEP 4.3- Heatmap of Feature Correlations"""

# Select numerical columns only
numerical_cols = df.select_dtypes(include='number').columns

# Compute correlation matrix
corr_matrix = df[numerical_cols].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Heatmap of Feature Correlations")
plt.show()

"""The heatmap visualizes the pairwise correlations between numerical features in the dataset.  

- Features like **Administrative** and **Administrative_Duration**, **ProductRelated** and **ProductRelated_Duration** show **strong positive correlations**,  
  indicating that **longer durations spent on administrative or product-related pages are associated with more page interactions**.  

- Moderate correlations can also be observed between **BounceRates** and **ExitRates**, suggesting that pages with high exit rates also tend to have higher bounce rates.  

- Understanding these relationships helps in feature selection and in interpreting model predictions later, especially when combined with SHAP explainability.

STEP 5- Check Skewness of Numerical Columns
"""

from sklearn.preprocessing import PowerTransformer

# -----------------------------
# 1Ô∏è‚É£ Skewness Table
# -----------------------------
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()

print("Initial skewness of numerical columns:")
skew_values = df[numerical_cols].skew().sort_values(ascending=False)
print(skew_values)

# -----------------------------
# 2Ô∏è‚É£ Plot original distributions
# -----------------------------
plt.figure(figsize=(15,12))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(5, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'{col} Distribution')
plt.tight_layout()
plt.show()

"""Conclusion: Almost all numerical features are right-skewed > 1

This means that most visitors have low values for metrics such as page duration, bounce rate, exit rate, etc., while a smaller group has very high browsing activity. These long right-tailed distributions can negatively affect machine learning model performance.

‚û°Ô∏è So transform or handle skewness

STEP 5.1-Transformation using (log/sqrt)
"""

# 3Ô∏è‚É£ Apply log1p / sqrt for positive or zero-adjustable columns
# -----------------------------
df_transformed = df.copy()
for col in numerical_cols:
    if df[col].min() > 0:
        # Positive-only ‚Üí log1p
        df_transformed[col] = np.log1p(df[col])
    else:
        # Zero or negative ‚Üí sqrt after shifting
        df_transformed[col] = np.sqrt(df[col] - df[col].min() + 1)

print("\nSkewness after log/sqrt transformation:")
print(df_transformed[numerical_cols].skew().sort_values(ascending=False))

"""STEP 5.2- Fix Skewness using yeo jhonson transformations"""

# 4Ô∏è‚É£ Apply Yeo‚ÄìJohnson for remaining skewed columns (|skew| > 0.75)
# -----------------------------
remaining_skewed = df_transformed[numerical_cols].skew().abs() > 0.75
cols_to_yeojohnson = df_transformed[numerical_cols].columns[remaining_skewed]

print("\nColumns to transform using Yeo-Johnson:")
print(list(cols_to_yeojohnson))

pt = PowerTransformer(method='yeo-johnson', standardize=False)
df_transformed[cols_to_yeojohnson] = pt.fit_transform(df_transformed[cols_to_yeojohnson])

print("\nSkewness after Yeo-Johnson transformation:")
print(df_transformed[numerical_cols].skew().sort_values(ascending=False))

"""To stabilize variance and improve model performance, Yeo‚ÄìJohnson transformation was chosen because:

It works for both positive and zero values

It reshapes skewed distributions closer to normal

It improves consistency for ML algorithms like Logistic Regression, SVM, etc.

üîπ Observation

Most numerical columns are now well-behaved (skewness ~ 0).

Only three columns remain heavily skewed:

Informational_Duration

Informational

PageValues

These are right-skewed (skew > 1.3),

STEP 5.3- QuantileTransformer (RankGauss)
"""

from sklearn.preprocessing import QuantileTransformer

cols_extremely_skewed = ['Informational_Duration', 'Informational', 'PageValues']

qt = QuantileTransformer(output_distribution='normal', n_quantiles=1000, random_state=42)
df_transformed[cols_extremely_skewed] = qt.fit_transform(df_transformed[cols_extremely_skewed])

# Check skewness after final transformation
print("\nSkewness after QuantileTransformer (final):")
print(df_transformed[cols_extremely_skewed].skew())

"""STEP 6- Detect outliers"""

# 5 Detect outliers using IQR method
# -----------------------------
outliers_summary = {}
for col in numerical_cols:
    Q1 = df_transformed[col].quantile(0.25)
    Q3 = df_transformed[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5*IQR
    upper = Q3 + 1.5*IQR
    outliers = df_transformed[(df_transformed[col] < lower) | (df_transformed[col] > upper)]
    outliers_summary[col] = len(outliers)

print("\nNumber of outliers detected per column:")
for col, count in outliers_summary.items():
    print(f"{col}: {count}")

"""STEP 6.1 ‚Äî Handle Outliers using Z-Score Method"""

from scipy import stats

# Copy the transformed dataframe
df_outliers_handled = df_transformed.copy()

# Set Z-score threshold
z_threshold = 3  # Commonly used threshold

# Dictionary to store number of outliers removed per column
outliers_removed = {}

for col in numerical_cols:
    # Compute Z-scores
    z_scores = np.abs(stats.zscore(df_outliers_handled[col]))

    # Find indices where Z-score > threshold
    outlier_indices = np.where(z_scores > z_threshold)[0]

    # Count outliers
    outliers_removed[col] = len(outlier_indices)

    # Remove outliers by capping at the threshold
    upper_limit = df_outliers_handled[col].mean() + z_threshold*df_outliers_handled[col].std()
    lower_limit = df_outliers_handled[col].mean() - z_threshold*df_outliers_handled[col].std()

    df_outliers_handled[col] = np.where(df_outliers_handled[col] > upper_limit, upper_limit,
                                        np.where(df_outliers_handled[col] < lower_limit, lower_limit,
                                                 df_outliers_handled[col]))

# Print summary
print("\nNumber of outliers handled per column using Z-score:")
for col, count in outliers_removed.items():
    print(f"{col}: {count}")

"""Observations

Most numerical columns are now skew-corrected and outliers handled.

Columns with extreme zero-inflation (SpecialDay, BounceRates) still have many small-value clusters, but the most extreme peaks have been capped.

Dataset is now ML-ready, with normalized distributions and outliers addressed.

STEP 6.2- SKEWNESS COMPARISON
"""

# Select numerical columns
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()

# Skewness before any transformation
skew_before = df[numerical_cols].skew()

# Skewness after transformations (log/sqrt + Yeo-Johnson + outlier handling)
skew_after = df_outliers_handled[numerical_cols].skew()

# Combine into a single DataFrame for comparison
skew_comparison = pd.DataFrame({
    'Skew_Before': skew_before,
    'Skew_After': skew_after
}).sort_values(by='Skew_Before', ascending=False)

# Display
print(skew_comparison)

"""STEP 6.3- VISUALISATION OF SKEWNESS COMPARISON"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create bar plot for skewness comparison
plt.figure(figsize=(12,6))
skew_comparison.sort_values('Skew_Before', ascending=False, inplace=True)

bar_width = 0.35
indices = np.arange(len(skew_comparison))

# Bars for before and after
plt.bar(indices, skew_comparison['Skew_Before'], bar_width, label='Skew Before', color='salmon')
plt.bar(indices + bar_width, skew_comparison['Skew_After'], bar_width, label='Skew After', color='skyblue')

# Labels and titles
plt.xticks(indices + bar_width/2, skew_comparison.index, rotation=45, ha='right')
plt.ylabel('Skewness')
plt.title('Comparison of Skewness Before vs After Transformation')
plt.legend()
plt.tight_layout()

# Show plot
plt.show()

"""STEP 7- Categorical Encoding & Preprocessing"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Define target column
target = 'Revenue'

# Identify categorical columns
categorical_cols = df_outliers_handled.select_dtypes(include='object').columns.tolist()

# Separate features and target
X = df_outliers_handled.drop(target, axis=1)
y = df_outliers_handled[target]

# Split dataset (train-test) before scaling/encoding to avoid data leakage
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Preprocessing pipeline: scale numerical, encode categorical
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)

# Fit and transform training data, transform test data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# Check shapes
print("--- Preprocessing Completed ---")
print("X_train shape:", X_train_processed.shape)
print("X_test shape:", X_test_processed.shape)

"""STEP 8-Check Imbalance"""

# Check target distribution
class_counts = y.value_counts()
class_percent = y.value_counts(normalize=True) * 100

print("Class counts:\n", class_counts)
print("\nClass percentage:\n", class_percent)

# Optional: visualize
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(6,4))
sns.countplot(x=y)
plt.title('Target Class Distribution')
plt.show()

"""1Ô∏è‚É£ Observation: Imbalance

Your target column is Revenue (binary classification):

False: 10,297 (~84.4%) ‚Üí majority class

True: 1,908 (~15.6%) ‚Üí minority class

STEP 8.1- Handle Imbalance with SMOTE (Training Set Only)
"""

from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Initialize SMOTE
smote = SMOTE(random_state=42)

# Apply SMOTE only on training data
X_train_res, y_train_res = smote.fit_resample(X_train_processed, y_train)

# Check new distribution
import pandas as pd
print("Class distribution after SMOTE on training data:")
print(pd.Series(y_train_res).value_counts())

"""Now training dataset is perfectly balanced:

This ensures the model will learn equally from both classes and not be biased toward the majority class.

Dataset is ready for modeling.

MACHINE LEARNING MODEL TRAINING AND EVALUATION

STEP 1. IMPORT LIBRARIES FOR ML
"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

"""Step 2: Model Training and Evaluation"""

# Train Random Forest classifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

model = RandomForestClassifier(random_state=42)
model.fit(X_train_res, y_train_res)

# Predict on original test set
y_pred = model.predict(X_test_processed)

# Evaluation
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""True Negatives (TN): 1921 ‚Üí correctly predicted False

False Positives (FP): 138 ‚Üí incorrectly predicted True

False Negatives (FN): 118 ‚Üí incorrectly predicted False

True Positives (TP): 264 ‚Üí correctly predicted True

STEP 3- Feature Importance

STEP 3.1-Extract Feature Names After ColumnTransformer
"""

# Get categorical feature names from OneHotEncoder
cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)

# Combine numerical + categorical feature names
feature_names = np.concatenate([numerical_cols, cat_features])

"""STEP 3.2- Get Feature Importances from Random Forest"""

# Feature importances
importances = model.feature_importances_

# Create DataFrame
feat_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Plot top 20 features
plt.figure(figsize=(10,8))
sns.barplot(x='Importance', y='Feature', data=feat_importance_df.head(20), palette='viridis')
plt.title('Top 20 Feature Importances from Random Forest')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""Top Predictive Features

These are the variables that contribute the most to predicting the target:

Predict_values ‚Äî Highest importance
‚Üí Indicates this feature has the strongest influence on the model‚Äôs decisions.

Exitrates

product_related_duration

STEP 4- BUILD AND TRAIN MULTIPLE MODELS
"""

print("\n--- Step 4: Training Multiple Models ---")

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier

# Dictionary to store trained models
models = {}

# -----------------------------
# 1. Logistic Regression
# -----------------------------
print("Training Logistic Regression...")
lr_model = LogisticRegression(solver='liblinear', random_state=42)
lr_model.fit(X_train_res, y_train_res)
models['Logistic Regression'] = lr_model

# -----------------------------
# 2. Random Forest
# -----------------------------
print("Training Random Forest...")
rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
rf_model.fit(X_train_res, y_train_res)
models['Random Forest'] = rf_model

# -----------------------------
# 3. LightGBM
# -----------------------------
print("Training LightGBM...")
lgbm_model = LGBMClassifier(random_state=42, n_jobs=-1)
lgbm_model.fit(X_train_res, y_train_res)
models['LightGBM'] = lgbm_model

print("\n--- All Models Trained Successfully ---")

"""STEP 4.1 -FINAL SUMMARY TABLE"""

print("\n--- Model Evaluation on Test Set ---\n")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

results = []

for model_name, model in models.items():
    print(f"Evaluating {model_name}...")
    y_pred = model.predict(X_test_processed)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append([model_name, accuracy, precision, recall, f1])

# Create comparison table
results_df = pd.DataFrame(results, columns=["Model", "Accuracy", "Precision", "Recall", "F1 Score"])
results_df = results_df.sort_values(by="F1 Score", ascending=False).reset_index(drop=True)

print("\n--- Model Comparison Table ---")
results_df

"""STEP 4.2- Visual Comparison of Models"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set plot style
sns.set(style="whitegrid")
plt.figure(figsize=(10,6))

# Melt the results_df for easy plotting
plot_df = results_df.melt(id_vars="Model", var_name="Metric", value_name="Score")

# Create grouped barplot
sns.barplot(x="Model", y="Score", hue="Metric", data=plot_df, palette="Set2")

# Add titles and labels
plt.title("Comparison of Model Performance Metrics", fontsize=16)
plt.ylabel("Score")
plt.ylim(0, 1)
plt.legend(title="Metric")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

"""Insights

Ensemble models (Random Forest, LightGBM) perform better than a linear model (Logistic Regression) on this dataset.

LightGBM is slightly better overall, but Random Forest has slightly better recall ‚Äî useful if capturing positive cases is critical.

Logistic Regression is simple but may underperform when relationships are nonlinear.

STEP 4.3-ROC-AUC Curve for All Models
"""

# --- ROC-AUC Curve for All Models ---
from sklearn.metrics import RocCurveDisplay  # <-- import added
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(8,6))

for model_name, model in models.items():
    RocCurveDisplay.from_estimator(model, X_test_processed, y_test, name=model_name, ax=ax)

# Random guess line
plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')

plt.title('ROC-AUC Curve Comparison')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('roc_auc_curve.png')
plt.show()

print("\n--- ROC-AUC evaluation complete. Plot saved as 'roc_auc_curve.png' ---")

predictions = lgbm_model.predict(X_test_df)
np.unique(predictions, return_counts=True)

# Correct mapping: True -> 'Yes', False -> 'No'
df_potential_customers = pd.DataFrame({
    'Customer_Index': range(len(X_test_df)),
    'predicted_purchase': pd.Series(predictions).map({True: 'Yes', False: 'No'})
})

"""STEP 5-Final Insight: Predicted Customers"""

# ================================
# ‚úÖ Final Insight: Predicted Customers
# ================================

try:
    print("\n--- Generating Predicted Customers ---\n")

    # 1Ô∏è‚É£ Transform the original X_test using the fitted preprocessor
    X_test_transformed = preprocessor.transform(X_test)

    # 2Ô∏è‚É£ Extract feature names from preprocessor
    cat_features_train = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)
    all_features_train = np.concatenate([numerical_cols, cat_features_train])

    # 3Ô∏è‚É£ Convert to DataFrame with proper feature names
    X_test_df = pd.DataFrame(X_test_transformed, columns=all_features_train)

    # 4Ô∏è‚É£ Ensure all training columns exist
    for col in all_features_train:
        if col not in X_test_df.columns:
            X_test_df[col] = 0

    # 5Ô∏è‚É£ Reorder columns exactly like training
    X_test_df = X_test_df[all_features_train]

    # 6Ô∏è‚É£ Predict using trained LightGBM model
    predictions = lgbm_model.predict(X_test_df)

    # 7Ô∏è‚É£ Map boolean predictions to "Yes"/"No"
    df_potential_customers = pd.DataFrame({
        'Customer_Index': range(len(X_test_df)),
        'predicted_purchase': pd.Series(predictions).map({True: 'Yes', False: 'No'})
    })

    # 8Ô∏è‚É£ Filter only predicted "Yes" customers
    df_potential_customers_yes = df_potential_customers[df_potential_customers['predicted_purchase'] == 'Yes']

    # 9Ô∏è‚É£ Display top 20 predicted customers
    print(df_potential_customers_yes.head(20))
    print(f"\nTotal predicted customers with purchase intention: {len(df_potential_customers_yes)} "
          f"out of {len(df_potential_customers)} test customers.")

    # üîü Save the final predicted list
    output_filename = 'predicted_customers.csv'
    df_potential_customers_yes.to_csv(output_filename, index=False)
    print(f"\nSuccessfully saved predicted customers to '{output_filename}'")

    # -------------------------------
    # Visualization & Reporting
    # -------------------------------

    # a) Distribution of predicted customers
    plt.figure(figsize=(6,4))
    sns.countplot(x='predicted_purchase', data=df_potential_customers, hue='predicted_purchase', dodge=False)
    plt.title("Predicted Customer Purchase Intention")
    plt.xlabel("Intention to Purchase")
    plt.ylabel("Number of Customers")
    plt.legend().remove()  # removes legend error
    plt.show()

    # b) Feature Importance Plot (Top 15 Features)
    importances = lgbm_model.feature_importances_
    feat_imp_df = pd.DataFrame({'Feature': all_features_train, 'Importance': importances})
    feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False).head(15)

    plt.figure(figsize=(10,6))
    sns.barplot(x='Importance', y='Feature', data=feat_imp_df, palette='coolwarm')
    plt.title("Top 15 Features Impacting Customer Purchase Intention")
    plt.xlabel("Importance Score")
    plt.ylabel("Feature")
    plt.show()

except NameError as e:
    print(f"\n!!! ERROR: {e} !!!")
    print("Please make sure the model and data preprocessing are completed first.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

"""| Metric                    | Value |
| ------------------------- | ----- |
| Total Test Customers      | 2,441 |
| Predicted to Purchase     | 383   |
| Predicted Not to Purchase | 2,058 |
| Predicted Purchase %      | 15.7% |

"""

